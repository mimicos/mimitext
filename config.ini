[Settings]
# 1024 for gpt2, up to 2048 for gptneo
MaxInputLength = 1024
# cpu for cpu, or cuda for cuda; cuda:1 to use the second gpu
Device = cuda
# Run garbage collection after every full generation?
UseGC = yes
# yes is 16-bit; no is 32-bit
HalfPrecision = yes

# Binding to localhost (should) mean only you, at your computer, can access the program.
# It is possible to cleverly access this while it's running on a VM or other distant machine
# by using a proxy. You may wish to change the BindAddress to a real IP, if the machine is
# safely firewalled from the public. It is NOT meant to be public-facing!
BindAddress = localhost
BindPort = 31013

# Modified loading (default: no) is a feature by @arrmansa that puts some of GPT Neo into RAM
# allowing the model to fit onto a card with insufficient memory to store the whole thing.
# This will break models other than GPT Neo, and it will require cuda to be enabled.
# RamBlocks determines the split between GPU and system ram for this feature.
# Default: 7. Valid values: 2~32.
# NOTE: This is incompatible with @finetuneanon's fork of transformers; it will just crash.
ModifiedLoading = no
RamBlocks = 7